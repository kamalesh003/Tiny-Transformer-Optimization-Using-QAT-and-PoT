{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Model and Data Preparation**"
      ],
      "metadata": {
        "id": "IrmcTEPhPy5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "import time\n",
        "from collections import deque\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on device:\", device)\n",
        "\n",
        "# Try to import torchvision; fallback to synthetic dataset if missing.\n",
        "try:\n",
        "    from torchvision import datasets, transforms\n",
        "    has_torchvision = True\n",
        "except Exception as e:\n",
        "    print(\"torchvision import failed, falling back to synthetic dataset. Error:\", e)\n",
        "    has_torchvision = False\n",
        "\n",
        "# ----------------- Utilities -----------------\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def model_size_bytes(model):\n",
        "    return sum(p.numel() * p.element_size() for p in model.parameters())\n",
        "\n",
        "def compute_sparsity(model):\n",
        "    total = 0\n",
        "    zeros = 0\n",
        "    for p in model.parameters():\n",
        "        if p.requires_grad:\n",
        "            total += p.numel()\n",
        "            zeros += (p.data == 0).sum().item()\n",
        "    return zeros / total if total>0 else 0.0\n",
        "\n",
        "\n",
        "# ----------------- Tiny ViT-style model -----------------\n",
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, in_ch=3, patch_size=4, emb_dim=64, img_size=32):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.n_patches = (img_size // patch_size) ** 2\n",
        "        self.proj = nn.Conv2d(in_ch, emb_dim, kernel_size=patch_size, stride=patch_size)\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x)\n",
        "        x = x.flatten(2).transpose(1,2)\n",
        "        return x\n",
        "\n",
        "class TinyAttention(nn.Module):\n",
        "    def __init__(self, emb_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        assert emb_dim % num_heads == 0\n",
        "        self.head_dim = emb_dim // num_heads\n",
        "        self.qkv = nn.Linear(emb_dim, emb_dim * 3)\n",
        "        self.out = nn.Linear(emb_dim, emb_dim)\n",
        "    def forward(self, x):\n",
        "        B, N, D = x.shape\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.reshape(B, N, 3, self.num_heads, self.head_dim).permute(2,0,3,1,4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        score = (q @ k.transpose(-2,-1)) / math.sqrt(self.head_dim)\n",
        "        att = F.softmax(score, dim=-1)\n",
        "        out = (att @ v).transpose(1,2).reshape(B, N, D)\n",
        "        return self.out(out)\n",
        "\n",
        "class TinyMLP(nn.Module):\n",
        "    def __init__(self, emb_dim, mlp_factor=2):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(emb_dim, emb_dim * mlp_factor)\n",
        "        self.fc2 = nn.Linear(emb_dim * mlp_factor, emb_dim)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, emb_dim, num_heads, mlp_factor=2, drop=0.0):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.attn = TinyAttention(emb_dim, num_heads)\n",
        "        self.norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.mlp = TinyMLP(emb_dim, mlp_factor)\n",
        "    def forward(self, x, fifo_sim=None, tile_size=None):\n",
        "        # If fifo_sim True and tile_size provided, process tokens in tiles to simulate FIFO streaming.\n",
        "        if fifo_sim and tile_size is not None:\n",
        "            B, N, D = x.shape\n",
        "            out_tokens = []\n",
        "            for i in range(0, N, tile_size):\n",
        "                chunk = x[:, i:i+tile_size, :]\n",
        "                chunk = chunk + self.attn(self.norm1(chunk))\n",
        "                chunk = chunk + self.mlp(self.norm2(chunk))\n",
        "                out_tokens.append(chunk)\n",
        "                fifo_sim.append(chunk.detach())  # producer writes chunk to FIFO (simulation)\n",
        "            x_new = torch.cat(out_tokens, dim=1)\n",
        "            return x_new\n",
        "        else:\n",
        "            y = x + self.attn(self.norm1(x))\n",
        "            y = y + self.mlp(self.norm2(y))\n",
        "            return y\n",
        "\n",
        "class TinyTransformer(nn.Module):\n",
        "    def __init__(self, img_size=32, patch_size=4, in_ch=3, emb_dim=64, depth=4, num_heads=4, mlp_factor=2, n_classes=10):\n",
        "        super().__init__()\n",
        "        self.patch = PatchEmbedding(in_ch, patch_size, emb_dim, img_size)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1,1,emb_dim))\n",
        "        self.pos_embed = nn.Parameter(torch.randn(1, 1 + self.patch.n_patches, emb_dim))\n",
        "        self.layers = nn.ModuleList([TransformerBlock(emb_dim, num_heads, mlp_factor) for _ in range(depth)])\n",
        "        self.norm = nn.LayerNorm(emb_dim)\n",
        "        self.head = nn.Linear(emb_dim, n_classes)\n",
        "\n",
        "    def forward(self, x, fifo_sim=False, tile_size=None):\n",
        "        B = x.shape[0]\n",
        "        x = self.patch(x)\n",
        "        cls = self.cls_token.expand(B, -1, -1)\n",
        "        x = torch.cat([cls, x], dim=1) + self.pos_embed\n",
        "\n",
        "        # ✅ FIX: create a real deque when fifo_sim=True\n",
        "        fifo = deque(maxlen=4) if fifo_sim else None\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, fifo_sim=fifo, tile_size=tile_size)  # pass actual deque or None\n",
        "\n",
        "        x = self.norm(x)\n",
        "        cls_final = x[:,0]\n",
        "        return self.head(cls_final)\n",
        "\n",
        "\n",
        "\n",
        "# ----------------- SparseNAS-style magnitude pruning -----------------\n",
        "def magnitude_prune_global(model, target_sparsity):\n",
        "    all_weights = torch.cat([p.data.abs().flatten() for p in model.parameters() if p.requires_grad])\n",
        "    k = int(all_weights.numel() * target_sparsity)\n",
        "    if k == 0:\n",
        "        return None\n",
        "    threshold = all_weights.kthvalue(k).values.item()\n",
        "    masks = {}\n",
        "    for name, p in model.named_parameters():\n",
        "        if p.requires_grad:\n",
        "            mask = (p.data.abs() > threshold).float()\n",
        "            p.data.mul_(mask)\n",
        "            masks[name] = mask\n",
        "    return masks\n",
        "\n",
        "def apply_mask(model, masks):\n",
        "    if masks is None:\n",
        "        return\n",
        "    for name, p in model.named_parameters():\n",
        "        if name in masks:\n",
        "            p.data.mul_(masks[name])\n",
        "\n",
        "# ----------------- SOAQ PoT quantization (STE) -----------------\n",
        "class PoTQuantizer(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, n_bits=4, signed=True, eps=1e-12):\n",
        "        ctx.save_for_backward(x)\n",
        "        sign = x.sign()\n",
        "        mag = x.abs().clamp(min=eps)\n",
        "        exponent = mag.log2().round()\n",
        "        q = sign * (2.0 ** exponent)\n",
        "        max_exp = 2**(n_bits-1) - 1\n",
        "        min_exp = -max_exp\n",
        "        q = sign * (2.0 ** exponent.clamp(min=min_exp, max=max_exp))\n",
        "        q[(mag < 2.0 ** min_exp).squeeze()] = 0.0\n",
        "        return q\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        (x,) = ctx.saved_tensors\n",
        "        return grad_output, None, None, None\n",
        "\n",
        "def pot_quantize_tensor(x, n_bits=4):\n",
        "    return PoTQuantizer.apply(x, n_bits)\n",
        "\n",
        "class QuantLinear(nn.Module):\n",
        "    def __init__(self, linear_module, n_bits=4):\n",
        "        super().__init__()\n",
        "        self.linear = linear_module\n",
        "        self.n_bits = n_bits\n",
        "    def forward(self, x):\n",
        "        qW = pot_quantize_tensor(self.linear.weight, self.n_bits)\n",
        "        if self.linear.bias is not None:\n",
        "            qB = pot_quantize_tensor(self.linear.bias, self.n_bits)\n",
        "        else:\n",
        "            qB = None\n",
        "        return F.linear(x, qW, qB)\n",
        "\n",
        "def quantize_model_inplace(model, n_bits=4):\n",
        "    # recursively replace Linear modules with QuantLinear wrappers\n",
        "    for name, module in list(model.named_children()):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            setattr(model, name, QuantLinear(module, n_bits=n_bits))\n",
        "        else:\n",
        "            quantize_model_inplace(module, n_bits=n_bits)\n",
        "\n",
        "# ----------------- Training / evaluation / inference -----------------\n",
        "def train_one_epoch(model, optimizer, loader, epoch, device, qn_bits=4, fifo_tile=None):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (x,y) in enumerate(loader):\n",
        "        x = x.to(device); y = y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x, fifo_sim=(fifo_tile is not None), tile_size=fifo_tile)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        total += x.size(0)\n",
        "        correct += (preds == y).sum().item()\n",
        "    return total_loss/total, correct/total\n",
        "\n",
        "def evaluate(model, loader, device, fifo_tile=None):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x = x.to(device); y = y.to(device)\n",
        "            logits = model(x, fifo_sim=(fifo_tile is not None), tile_size=fifo_tile)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            total += x.size(0)\n",
        "            correct += (preds == y).sum().item()\n",
        "    return correct/total\n",
        "\n",
        "def inference_single(model, img_tensor, device, fifo_tile=None):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x = img_tensor.unsqueeze(0).to(device)\n",
        "        logits = model(x, fifo_sim=(fifo_tile is not None), tile_size=fifo_tile)\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        pred = logits.argmax(dim=1).item()\n",
        "    return pred, probs.squeeze(0).cpu().numpy()\n",
        "\n",
        "# ----------------- Data loaders (CIFAR-10 or synthetic fallback) -----------------\n",
        "def get_cifar10_dataloaders(batch_size=64, subset_train=4000, subset_val=1000):\n",
        "    if has_torchvision:\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        transform_test = transforms.Compose([transforms.ToTensor()])\n",
        "        trainset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform_train)\n",
        "        testset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform_test)\n",
        "        train_subset = Subset(trainset, list(range(min(subset_train, len(trainset)))))\n",
        "        val_subset = Subset(trainset, list(range(min(subset_train, len(trainset)), min(subset_train+subset_val, len(trainset)))))\n",
        "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "        test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    else:\n",
        "        print(\"Creating synthetic dataset (CIFAR-10 like) for demo.\")\n",
        "        num_train = subset_train\n",
        "        num_val = subset_val\n",
        "        num_test = 1000\n",
        "        X_train = torch.randn(num_train, 3, 32, 32)\n",
        "        y_train = torch.randint(0, 10, (num_train,))\n",
        "        X_val = torch.randn(num_val, 3, 32, 32)\n",
        "        y_val = torch.randint(0, 10, (num_val,))\n",
        "        X_test = torch.randn(num_test, 3, 32, 32)\n",
        "        y_test = torch.randint(0, 10, (num_test,))\n",
        "        train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size, shuffle=False)\n",
        "        test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# ----------------- proxy SuperNAS: random search -----------------\n",
        "def random_search_supernet(search_space, train_loader, val_loader, budget=4, epochs=1, device=device):\n",
        "    best = None\n",
        "    best_acc = -1.0\n",
        "    for i in range(budget):\n",
        "        cfg = random.choice(search_space)\n",
        "        print(f\"\\n[Search {i+1}/{budget}] Trying config: {cfg}\")\n",
        "        model = TinyTransformer(img_size=32, patch_size=4, emb_dim=cfg['emb_dim'], depth=cfg['depth'],\n",
        "                                num_heads=cfg['num_heads'], mlp_factor=cfg['mlp_factor']).to(device)\n",
        "        print(\" Params:\", count_parameters(model), \" Size (bytes):\", model_size_bytes(model))\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "        for e in range(epochs):\n",
        "            train_one_epoch(model, optimizer, train_loader, e, device, fifo_tile=None)\n",
        "        acc = evaluate(model, val_loader, device)\n",
        "        print(\" Validation acc:\", acc)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best = (cfg, model)\n",
        "    return best, best_acc\n",
        "\n",
        "# ----------------- Full pipeline runner -----------------\n",
        "def run_pipeline(seed=42, quick_mode=True):\n",
        "    random.seed(seed); torch.manual_seed(seed)\n",
        "    batch_size = 64\n",
        "    train_loader, val_loader, test_loader = get_cifar10_dataloaders(batch_size=batch_size,\n",
        "                                                                    subset_train=2000 if quick_mode else 40000,\n",
        "                                                                    subset_val=500 if quick_mode else 5000)\n",
        "    search_space = [\n",
        "        {'emb_dim':64, 'depth':2, 'num_heads':2, 'mlp_factor':2},\n",
        "        {'emb_dim':64, 'depth':3, 'num_heads':2, 'mlp_factor':2},\n",
        "        {'emb_dim':128, 'depth':3, 'num_heads':4, 'mlp_factor':2},\n",
        "        {'emb_dim':128, 'depth':4, 'num_heads':4, 'mlp_factor':2},\n",
        "        {'emb_dim':64, 'depth':4, 'num_heads':4, 'mlp_factor':2},\n",
        "    ]\n",
        "    (best_cfg, best_model), best_acc = random_search_supernet(search_space, train_loader, val_loader, budget=4, epochs=1, device=device)\n",
        "    print(\"\\nSelected architecture:\", best_cfg, \"val_acc:\", best_acc)\n",
        "    model = best_model\n",
        "    # SparseNAS-style pruning\n",
        "    target_sparsity = 0.6\n",
        "    print(\"\\nApplying global magnitude pruning to target sparsity\", target_sparsity)\n",
        "    masks = magnitude_prune_global(model, target_sparsity)\n",
        "    print(\"Sparsity after prune (measured):\", compute_sparsity(model))\n",
        "    # Fine-tune a bit\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
        "    for e in range(2):\n",
        "        train_one_epoch(model, optimizer, train_loader, e, device)\n",
        "    val_acc_post_prune = evaluate(model, val_loader, device)\n",
        "    print(\"Validation acc after pruning & fine-tune:\", val_acc_post_prune)\n",
        "    # SOAQ quantization (QAT)\n",
        "    qn_bits = 4\n",
        "    print(\"\\nApplying PoT quantization wrappers (n_bits=\", qn_bits, \")\")\n",
        "    quantize_model_inplace(model, n_bits=qn_bits)\n",
        "    apply_mask(model, masks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
        "    for e in range(2):\n",
        "        train_one_epoch(model, optimizer, train_loader, e, device)\n",
        "    val_acc_post_qat = evaluate(model, val_loader, device)\n",
        "    print(\"Validation acc after PoT-QAT:\", val_acc_post_qat)\n",
        "    # FIFO token-tiling simulation\n",
        "    fifo_tile = 8\n",
        "    print(\"\\nEvaluating with FIFO-token-tiling simulation (tile_size=%d)\" % fifo_tile)\n",
        "    val_acc_fifo = evaluate(model, val_loader, device, fifo_tile=fifo_tile)\n",
        "    print(\"Validation acc with FIFO simulation:\", val_acc_fifo)\n",
        "    # Final test\n",
        "    test_acc = evaluate(model, test_loader, device, fifo_tile=fifo_tile)\n",
        "    final_sparsity = compute_sparsity(model)\n",
        "    param_count = count_parameters(model)\n",
        "    size_bytes = model_size_bytes(model)\n",
        "    print(\"\\n=== Final Results ===\")\n",
        "    print(\"Test accuracy:\", test_acc)\n",
        "    print(\"Validation accuracy (post-QAT):\", val_acc_post_qat)\n",
        "    print(\"Parameter count:\", param_count)\n",
        "    print(\"Model size (bytes):\", size_bytes)\n",
        "    print(\"Measured sparsity:\", final_sparsity)\n",
        "    test_iter = iter(test_loader)\n",
        "    imgs, labels = next(test_iter)\n",
        "    img0 = imgs[0]\n",
        "    pred, probs = inference_single(model, img0, device, fifo_tile=fifo_tile)\n",
        "    print(\"Example inference -> label:\", labels[0].item(), \"pred:\", pred)\n",
        "    results = {\n",
        "        'test_acc': test_acc,\n",
        "        'val_acc_post_qat': val_acc_post_qat,\n",
        "        'param_count': param_count,\n",
        "        'size_bytes': size_bytes,\n",
        "        'sparsity': final_sparsity,\n",
        "        'best_cfg': best_cfg,\n",
        "    }\n",
        "    return model, results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    t0 = time.time()\n",
        "    model, results = run_pipeline(seed=123, quick_mode=True)\n",
        "    t1 = time.time()\n",
        "    print(\"Pipeline runtime (s):\", t1-t0)\n",
        "    print(\"Results:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cntxhP8VPXWg",
        "outputId": "c882ead1-5f41-4022-e7ff-0327febbb49d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 37.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Search 1/4] Trying config: {'emb_dim': 64, 'depth': 2, 'num_heads': 2, 'mlp_factor': 2}\n",
            " Params: 75082  Size (bytes): 300328\n",
            " Validation acc: 0.13\n",
            "\n",
            "[Search 2/4] Trying config: {'emb_dim': 128, 'depth': 3, 'num_heads': 4, 'mlp_factor': 2}\n",
            " Params: 413706  Size (bytes): 1654824\n",
            " Validation acc: 0.166\n",
            "\n",
            "[Search 3/4] Trying config: {'emb_dim': 64, 'depth': 2, 'num_heads': 2, 'mlp_factor': 2}\n",
            " Params: 75082  Size (bytes): 300328\n",
            " Validation acc: 0.146\n",
            "\n",
            "[Search 4/4] Trying config: {'emb_dim': 128, 'depth': 4, 'num_heads': 4, 'mlp_factor': 2}\n",
            " Params: 546186  Size (bytes): 2184744\n",
            " Validation acc: 0.176\n",
            "\n",
            "Selected architecture: {'emb_dim': 128, 'depth': 4, 'num_heads': 4, 'mlp_factor': 2} val_acc: 0.176\n",
            "\n",
            "Applying global magnitude pruning to target sparsity 0.6\n",
            "Sparsity after prune (measured): 0.5999989014731245\n",
            "Validation acc after pruning & fine-tune: 0.212\n",
            "\n",
            "Applying PoT quantization wrappers (n_bits= 4 )\n",
            "Validation acc after PoT-QAT: 0.24\n",
            "\n",
            "Evaluating with FIFO-token-tiling simulation (tile_size=8)\n",
            "Validation acc with FIFO simulation: 0.23\n",
            "\n",
            "=== Final Results ===\n",
            "Test accuracy: 0.2153\n",
            "Validation accuracy (post-QAT): 0.24\n",
            "Parameter count: 546186\n",
            "Model size (bytes): 2184744\n",
            "Measured sparsity: 1.8308781257666803e-06\n",
            "Example inference -> label: 3 pred: 4\n",
            "Pipeline runtime (s): 23.3282310962677\n",
            "Results: {'test_acc': 0.2153, 'val_acc_post_qat': 0.24, 'param_count': 546186, 'size_bytes': 2184744, 'sparsity': 1.8308781257666803e-06, 'best_cfg': {'emb_dim': 128, 'depth': 4, 'num_heads': 4, 'mlp_factor': 2}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Full-scale run for maximum accuracy**"
      ],
      "metadata": {
        "id": "O4sVu37CPskQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Full-scale run for maximum accuracy\n",
        "model, results = run_pipeline(seed=123, quick_mode=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt6ZAgyzPefr",
        "outputId": "c44a6135-f178-49c1-f02b-cf1ea7f7bfec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Search 1/4] Trying config: {'emb_dim': 64, 'depth': 2, 'num_heads': 2, 'mlp_factor': 2}\n",
            " Params: 75082  Size (bytes): 300328\n",
            " Validation acc: 0.3082\n",
            "\n",
            "[Search 2/4] Trying config: {'emb_dim': 128, 'depth': 3, 'num_heads': 4, 'mlp_factor': 2}\n",
            " Params: 413706  Size (bytes): 1654824\n",
            " Validation acc: 0.3426\n",
            "\n",
            "[Search 3/4] Trying config: {'emb_dim': 64, 'depth': 2, 'num_heads': 2, 'mlp_factor': 2}\n",
            " Params: 75082  Size (bytes): 300328\n",
            " Validation acc: 0.297\n",
            "\n",
            "[Search 4/4] Trying config: {'emb_dim': 128, 'depth': 4, 'num_heads': 4, 'mlp_factor': 2}\n",
            " Params: 546186  Size (bytes): 2184744\n",
            " Validation acc: 0.3396\n",
            "\n",
            "Selected architecture: {'emb_dim': 128, 'depth': 3, 'num_heads': 4, 'mlp_factor': 2} val_acc: 0.3426\n",
            "\n",
            "Applying global magnitude pruning to target sparsity 0.6\n",
            "Sparsity after prune (measured): 0.5999985496947108\n",
            "Validation acc after pruning & fine-tune: 0.4244\n",
            "\n",
            "Applying PoT quantization wrappers (n_bits= 4 )\n",
            "Validation acc after PoT-QAT: 0.4512\n",
            "\n",
            "Evaluating with FIFO-token-tiling simulation (tile_size=8)\n",
            "Validation acc with FIFO simulation: 0.4616\n",
            "\n",
            "=== Final Results ===\n",
            "Test accuracy: 0.4883\n",
            "Validation accuracy (post-QAT): 0.4512\n",
            "Parameter count: 413706\n",
            "Model size (bytes): 1654824\n",
            "Measured sparsity: 0.0\n",
            "Example inference -> label: 3 pred: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding Best Config**"
      ],
      "metadata": {
        "id": "S2-CwiUnP9ZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Larger-scale setup\n",
        "train_loader, val_loader, test_loader = get_cifar10_dataloaders(batch_size=128,\n",
        "                                                                subset_train=40000,\n",
        "                                                                subset_val=5000)\n",
        "\n",
        "search_space = [\n",
        "    {'emb_dim': 64, 'depth': 3, 'num_heads': 2, 'mlp_factor': 2},\n",
        "    {'emb_dim': 128, 'depth': 4, 'num_heads': 4, 'mlp_factor': 2},\n",
        "    {'emb_dim': 192, 'depth': 6, 'num_heads': 6, 'mlp_factor': 2},\n",
        "    {'emb_dim': 256, 'depth': 8, 'num_heads': 8, 'mlp_factor': 2},\n",
        "]\n",
        "\n",
        "# === SuperNAS Search (more candidates, more epochs) ===\n",
        "(best_cfg, best_model), best_acc = random_search_supernet(\n",
        "    search_space, train_loader, val_loader, budget=6, epochs=5\n",
        ")\n",
        "\n",
        "print(\"Best configuration:\", best_cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-fZX9ukP65l",
        "outputId": "37313df3-d0bb-4fa1-ea44-a0b94aef712b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Search 1/6] Trying config: {'emb_dim': 192, 'depth': 6, 'num_heads': 6, 'mlp_factor': 2}\n",
            " Params: 1806538  Size (bytes): 7226152\n",
            " Validation acc: 0.4252\n",
            "\n",
            "[Search 2/6] Trying config: {'emb_dim': 64, 'depth': 3, 'num_heads': 2, 'mlp_factor': 2}\n",
            " Params: 108554  Size (bytes): 434216\n",
            " Validation acc: 0.4134\n",
            "\n",
            "[Search 3/6] Trying config: {'emb_dim': 64, 'depth': 3, 'num_heads': 2, 'mlp_factor': 2}\n",
            " Params: 108554  Size (bytes): 434216\n",
            " Validation acc: 0.4232\n",
            "\n",
            "[Search 4/6] Trying config: {'emb_dim': 256, 'depth': 8, 'num_heads': 8, 'mlp_factor': 2}\n",
            " Params: 4249354  Size (bytes): 16997416\n",
            " Validation acc: 0.351\n",
            "\n",
            "[Search 5/6] Trying config: {'emb_dim': 192, 'depth': 6, 'num_heads': 6, 'mlp_factor': 2}\n",
            " Params: 1806538  Size (bytes): 7226152\n",
            " Validation acc: 0.4354\n",
            "\n",
            "[Search 6/6] Trying config: {'emb_dim': 192, 'depth': 6, 'num_heads': 6, 'mlp_factor': 2}\n",
            " Params: 1806538  Size (bytes): 7226152\n",
            " Validation acc: 0.4306\n",
            "Best configuration: {'emb_dim': 192, 'depth': 6, 'num_heads': 6, 'mlp_factor': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pruning**"
      ],
      "metadata": {
        "id": "1aEdY6AvQE00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply pruning\n",
        "target_sparsity = 0.4\n",
        "masks = magnitude_prune_global(best_model, target_sparsity)\n",
        "print(\"Sparsity after pruning:\", compute_sparsity(best_model))\n",
        "\n",
        "# Fine-tune longer (e.g., 30 epochs)\n",
        "optimizer = torch.optim.Adam(best_model.parameters(), lr=5e-4)\n",
        "for e in range(30):\n",
        "    loss, acc = train_one_epoch(best_model, optimizer, train_loader, e, device)\n",
        "    print(f\"Epoch {e+1} | Loss: {loss:.4f} | Acc: {acc:.4f}\")\n",
        "\n",
        "val_acc = evaluate(best_model, val_loader, device)\n",
        "print(\"Validation accuracy after fine-tune:\", val_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7CYWqzUQCrX",
        "outputId": "95f4c028-b259-43f4-a0e5-bc7902da5ae3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity after pruning: 0.39999988929100855\n",
            "Epoch 1 | Loss: 1.4785 | Acc: 0.4637\n",
            "Epoch 2 | Loss: 1.4245 | Acc: 0.4833\n",
            "Epoch 3 | Loss: 1.3987 | Acc: 0.4965\n",
            "Epoch 4 | Loss: 1.3694 | Acc: 0.5039\n",
            "Epoch 5 | Loss: 1.3542 | Acc: 0.5085\n",
            "Epoch 6 | Loss: 1.3173 | Acc: 0.5234\n",
            "Epoch 7 | Loss: 1.3090 | Acc: 0.5275\n",
            "Epoch 8 | Loss: 1.2934 | Acc: 0.5325\n",
            "Epoch 9 | Loss: 1.2736 | Acc: 0.5374\n",
            "Epoch 10 | Loss: 1.2528 | Acc: 0.5480\n",
            "Epoch 11 | Loss: 1.2365 | Acc: 0.5552\n",
            "Epoch 12 | Loss: 1.2192 | Acc: 0.5592\n",
            "Epoch 13 | Loss: 1.2052 | Acc: 0.5647\n",
            "Epoch 14 | Loss: 1.1848 | Acc: 0.5745\n",
            "Epoch 15 | Loss: 1.1615 | Acc: 0.5850\n",
            "Epoch 16 | Loss: 1.1499 | Acc: 0.5866\n",
            "Epoch 17 | Loss: 1.1307 | Acc: 0.5925\n",
            "Epoch 18 | Loss: 1.1192 | Acc: 0.5994\n",
            "Epoch 19 | Loss: 1.1015 | Acc: 0.6030\n",
            "Epoch 20 | Loss: 1.0860 | Acc: 0.6099\n",
            "Epoch 21 | Loss: 1.0690 | Acc: 0.6155\n",
            "Epoch 22 | Loss: 1.0490 | Acc: 0.6221\n",
            "Epoch 23 | Loss: 1.0292 | Acc: 0.6272\n",
            "Epoch 24 | Loss: 1.0131 | Acc: 0.6390\n",
            "Epoch 25 | Loss: 0.9985 | Acc: 0.6430\n",
            "Epoch 26 | Loss: 0.9775 | Acc: 0.6491\n",
            "Epoch 27 | Loss: 0.9632 | Acc: 0.6555\n",
            "Epoch 28 | Loss: 0.9475 | Acc: 0.6583\n",
            "Epoch 29 | Loss: 0.9220 | Acc: 0.6672\n",
            "Epoch 30 | Loss: 0.9080 | Acc: 0.6753\n",
            "Validation accuracy after fine-tune: 0.5848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply QAT**"
      ],
      "metadata": {
        "id": "9rOim6HiQZuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply quantization wrappers (QAT)\n",
        "quantize_model_inplace(best_model, n_bits=4)\n",
        "apply_mask(best_model, masks)  # Reapply pruning mask after quantization\n",
        "\n",
        "optimizer = torch.optim.Adam(best_model.parameters(), lr=2e-4)\n",
        "\n",
        "# Train longer (50 epochs recommended)\n",
        "for e in range(50):\n",
        "    loss, acc = train_one_epoch(best_model, optimizer, train_loader, e, device)\n",
        "    print(f\"QAT Epoch {e+1} | Loss: {loss:.4f} | Acc: {acc:.4f}\")\n",
        "\n",
        "val_acc_post_qat = evaluate(best_model, val_loader, device)\n",
        "print(\"Validation accuracy after QAT:\", val_acc_post_qat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBBDHWCwQWI7",
        "outputId": "7a5d1f84-2770-47ca-b09f-a169e137bc4d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QAT Epoch 1 | Loss: 0.8316 | Acc: 0.7021\n",
            "QAT Epoch 2 | Loss: 0.7949 | Acc: 0.7150\n",
            "QAT Epoch 3 | Loss: 0.7697 | Acc: 0.7244\n",
            "QAT Epoch 4 | Loss: 0.7612 | Acc: 0.7278\n",
            "QAT Epoch 5 | Loss: 0.7378 | Acc: 0.7357\n",
            "QAT Epoch 6 | Loss: 0.7239 | Acc: 0.7400\n",
            "QAT Epoch 7 | Loss: 0.7129 | Acc: 0.7424\n",
            "QAT Epoch 8 | Loss: 0.6966 | Acc: 0.7487\n",
            "QAT Epoch 9 | Loss: 0.6861 | Acc: 0.7517\n",
            "QAT Epoch 10 | Loss: 0.6731 | Acc: 0.7599\n",
            "QAT Epoch 11 | Loss: 0.6644 | Acc: 0.7594\n",
            "QAT Epoch 12 | Loss: 0.6492 | Acc: 0.7680\n",
            "QAT Epoch 13 | Loss: 0.6345 | Acc: 0.7737\n",
            "QAT Epoch 14 | Loss: 0.6249 | Acc: 0.7754\n",
            "QAT Epoch 15 | Loss: 0.6122 | Acc: 0.7792\n",
            "QAT Epoch 16 | Loss: 0.5910 | Acc: 0.7869\n",
            "QAT Epoch 17 | Loss: 0.5849 | Acc: 0.7915\n",
            "QAT Epoch 18 | Loss: 0.5783 | Acc: 0.7926\n",
            "QAT Epoch 19 | Loss: 0.5673 | Acc: 0.7955\n",
            "QAT Epoch 20 | Loss: 0.5548 | Acc: 0.8004\n",
            "QAT Epoch 21 | Loss: 0.5373 | Acc: 0.8080\n",
            "QAT Epoch 22 | Loss: 0.5240 | Acc: 0.8090\n",
            "QAT Epoch 23 | Loss: 0.5161 | Acc: 0.8154\n",
            "QAT Epoch 24 | Loss: 0.5060 | Acc: 0.8178\n",
            "QAT Epoch 25 | Loss: 0.4911 | Acc: 0.8238\n",
            "QAT Epoch 26 | Loss: 0.4924 | Acc: 0.8224\n",
            "QAT Epoch 27 | Loss: 0.4745 | Acc: 0.8285\n",
            "QAT Epoch 28 | Loss: 0.4638 | Acc: 0.8325\n",
            "QAT Epoch 29 | Loss: 0.4472 | Acc: 0.8380\n",
            "QAT Epoch 30 | Loss: 0.4455 | Acc: 0.8389\n",
            "QAT Epoch 31 | Loss: 0.4271 | Acc: 0.8461\n",
            "QAT Epoch 32 | Loss: 0.4219 | Acc: 0.8494\n",
            "QAT Epoch 33 | Loss: 0.4113 | Acc: 0.8514\n",
            "QAT Epoch 34 | Loss: 0.3977 | Acc: 0.8558\n",
            "QAT Epoch 35 | Loss: 0.3939 | Acc: 0.8581\n",
            "QAT Epoch 36 | Loss: 0.3837 | Acc: 0.8623\n",
            "QAT Epoch 37 | Loss: 0.3715 | Acc: 0.8665\n",
            "QAT Epoch 38 | Loss: 0.3701 | Acc: 0.8663\n",
            "QAT Epoch 39 | Loss: 0.3573 | Acc: 0.8716\n",
            "QAT Epoch 40 | Loss: 0.3554 | Acc: 0.8712\n",
            "QAT Epoch 41 | Loss: 0.3360 | Acc: 0.8793\n",
            "QAT Epoch 42 | Loss: 0.3343 | Acc: 0.8802\n",
            "QAT Epoch 43 | Loss: 0.3245 | Acc: 0.8823\n",
            "QAT Epoch 44 | Loss: 0.3190 | Acc: 0.8853\n",
            "QAT Epoch 45 | Loss: 0.3165 | Acc: 0.8869\n",
            "QAT Epoch 46 | Loss: 0.3067 | Acc: 0.8885\n",
            "QAT Epoch 47 | Loss: 0.3015 | Acc: 0.8899\n",
            "QAT Epoch 48 | Loss: 0.2840 | Acc: 0.8975\n",
            "QAT Epoch 49 | Loss: 0.2788 | Acc: 0.9001\n",
            "QAT Epoch 50 | Loss: 0.2727 | Acc: 0.9029\n",
            "Validation accuracy after QAT: 0.5956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=15)"
      ],
      "metadata": {
        "id": "CewHNQ9MQdIj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FIFO Tiling**"
      ],
      "metadata": {
        "id": "bkqAP2gtQgPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fifo_tile = 8\n",
        "test_acc = evaluate(best_model, test_loader, device, fifo_tile=fifo_tile)\n",
        "print(\"Final Test Accuracy with FIFO tiling:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqN4wRhWQetL",
        "outputId": "d591fd9a-fa6b-4741-fc7f-422f3c448299"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy with FIFO tiling: 0.6202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save Model**"
      ],
      "metadata": {
        "id": "odFvE2uBZ39H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(best_model.state_dict(), \"best_tiny_vit_qnn.pth\")"
      ],
      "metadata": {
        "id": "qV22TAs4ZhPp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform Inference in test set**"
      ],
      "metadata": {
        "id": "tL5TY6QvaPzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "loaded_model = TinyTransformer(img_size=32, patch_size=4, emb_dim=best_cfg['emb_dim'], depth=best_cfg['depth'],\n",
        "                               num_heads=best_cfg['num_heads'], mlp_factor=best_cfg['mlp_factor']).to(device)\n",
        "\n",
        "# Apply quantization wrappers BEFORE loading the state dictionary\n",
        "quantize_model_inplace(loaded_model, n_bits=4)\n",
        "\n",
        "loaded_model.load_state_dict(torch.load(\"/content/best_tiny_vit_qnn.pth\"))\n",
        "\n",
        "# Get a sample image from the test set\n",
        "test_iter = iter(test_loader)\n",
        "imgs, labels = next(test_iter)\n",
        "img0 = imgs[0]\n",
        "label0 = labels[0].item()\n",
        "\n",
        "# Perform inference\n",
        "pred, probs = inference_single(loaded_model, img0, device, fifo_tile=fifo_tile)\n",
        "\n",
        "print(f\"Inference result for sample image:\")\n",
        "print(f\"  True label: {label0}\")\n",
        "print(f\"  Predicted label: {pred}\")\n",
        "print(f\"  Probabilities: {probs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOcIPKBeaKh6",
        "outputId": "47635544-7ac4-4e6a-f26b-5d16ed0e1843"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference result for sample image:\n",
            "  True label: 3\n",
            "  Predicted label: 3\n",
            "  Probabilities: [9.2632581e-05 1.1458243e-05 3.0683666e-06 7.6642418e-01 6.4932391e-07\n",
            " 2.3242722e-01 2.0185883e-08 4.1080471e-06 1.9971824e-04 8.3690434e-04]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Metrics Visualization**"
      ],
      "metadata": {
        "id": "RQtx9SguarHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'results', 'best_acc', 'val_acc', and 'val_acc_post_qat', 'test_acc' are available\n",
        "\n",
        "metrics_labels = ['Initial Validation Acc (SuperNAS)', 'Validation Acc (Post-Fine-tune)',\n",
        "                  'Validation Acc (Post-QAT)', 'Test Acc (FIFO Sim)']\n",
        "\n",
        "# Collect the accuracy values, handling potential missing values if quick_mode was used\n",
        "accuracy_values = []\n",
        "\n",
        "# Initial Validation Accuracy from SuperNAS search\n",
        "accuracy_values.append(best_acc)\n",
        "\n",
        "# Validation Accuracy after fine-tuning (check if val_acc from larger run exists, otherwise use post-prune if available, or post-qat if neither)\n",
        "if 'val_acc' in globals():\n",
        "    accuracy_values.append(val_acc)\n",
        "    print(\"Using 'val_acc' for Validation Acc (Post-Fine-tune)\")\n",
        "elif 'val_acc_post_prune' in results:\n",
        "     accuracy_values.append(results['val_acc_post_prune'])\n",
        "     print(\"Using 'results['val_acc_post_prune']' for Validation Acc (Post-Fine-tune)\")\n",
        "else:\n",
        "    accuracy_values.append(results['val_acc_post_qat']) # Fallback\n",
        "    print(\"Using 'results['val_acc_post_qat']' for Validation Acc (Post-Fine-tune) as fallback\")\n",
        "\n",
        "\n",
        "# Validation Accuracy after QAT\n",
        "accuracy_values.append(val_acc_post_qat)\n",
        "\n",
        "# Test Accuracy\n",
        "accuracy_values.append(test_acc)\n",
        "\n",
        "\n",
        "x = np.arange(len(metrics_labels))\n",
        "width = 0.6 # Increased width for better visibility\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 7)) # Increased figure size\n",
        "rects = ax.bar(x, accuracy_values, width, color=['skyblue', 'lightgreen', 'salmon', 'gold'])\n",
        "\n",
        "# Add some text for labels, titles and axes ticks\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Model Accuracy at Different Pipeline Stages')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics_labels, rotation=0, ha='center') # No rotation needed with wider plot\n",
        "ax.set_ylim(0, 1) # Accuracy is between 0 and 1\n",
        "ax.grid(axis='y', linestyle='--', alpha=0.7) # Add a horizontal grid\n",
        "\n",
        "# Add accuracy values on top of the bars\n",
        "def autolabel(rects):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate(f'{height:.4f}',\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 5),  # 5 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom',\n",
        "                    fontsize=10)\n",
        "\n",
        "autolabel(rects)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Also display parameter count, size, and sparsity\n",
        "print(\"\\nOther Metrics:\")\n",
        "print(f\"Parameter Count: {results['param_count']}\")\n",
        "print(f\"Model Size (bytes): {results['size_bytes']}\")\n",
        "# Check if the sparsity from the larger run is available, otherwise use the one from results\n",
        "final_sparsity_value = compute_sparsity(loaded_model) if 'loaded_model' in globals() else results['sparsity']\n",
        "print(f\"Measured Sparsity: {final_sparsity_value:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "id": "cXGqSuC2akTf",
        "outputId": "74a38b9e-1c32-41ce-98e9-39f5852adfa0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 'val_acc' for Validation Acc (Post-Fine-tune)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Other Metrics:\n",
            "Parameter Count: 413706\n",
            "Model Size (bytes): 1654824\n",
            "Measured Sparsity: 0.000000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}